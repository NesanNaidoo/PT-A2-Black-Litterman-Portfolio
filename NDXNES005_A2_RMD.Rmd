---
title: "Appendix B : Code"
output: 
  pdf_document:
    latex_engine: xelatex
    keep_tex: true  
fontsize: 12pt
header-includes:
  - \usepackage{setspace}
  - \onehalfspacing
  - \usepackage{etoolbox}
  - \usepackage{float}
  - \usepackage{graphicx}
  - \usepackage{fvextra}
execute:
  warning: FALSE
  message: FALSE
  fig.width: 7        
  fig.height: 5       
results: asis
bibliography: Sources.bib  
nocite: '@*'
csl: _citation_style/apa.csl 
date: "`r Sys.Date()`"
---
Coding for this section was completed using RStudio 2024.09.0+375 ("Cranberry Hibiscus" Release) and was based on R and MATLAB code provided by Professor Tim Gebbie(STA4028Z).

### 2.1 Libraries [@Tim_prep]

```{r}
# load required libraries
suppressPackageStartupMessages({
library(openxlsx)     
library(timeSeries)   
library(xts)          
library(zoo)          
library(matrixStats) 
library(quadprog)     
library(knitr)        
library(dplyr)        
library(ggplot2)      
library(tidyr)  
library(PerformanceAnalytics)
})
```

### 2.2 Load data and preprocessing [@Tim_prep]

```{r}
# reading in all 4 sheets into a list
dfS <- list()
for (i in 1:4) {
  dfS[[i]] <- read.xlsx("_raw_data/PT-TAA-JSE-Daily-1994-2017.xlsx", sheet = i, detectDates = TRUE)
  cat("Sheet", i, "loaded with dimensions:", dim(dfS[[i]]), "\n")
}

# define entities and which assets to keep
Entities <- c('X1','STEFI','ALBI','J203','J500', sprintf("J5%d", seq(10,90,by=10)))
Items    <- c('Date','TRI','Stefi')

#cleaning each sheet
for (i in 1:4) {
  tI0 <- sapply(colnames(dfS[[i]]), function(x) any(grepl(paste(Entities, collapse="|"), x)))
  tI1 <- sapply(dfS[[i]][2,], function(x) any(grepl(paste(Items, collapse="|"), x)))
  tI  <- tI0 & tI1
  
  # remove header rows
  dfS[[i]] <- dfS[[i]][-c(1,2), tI]
  names(dfS[[i]])[1] <- "Date"
  
  newColNames <- strsplit(colnames(dfS[[i]]), ":")
  for(m in 2:length(newColNames)) names(dfS[[i]])[m] <- newColNames[[m]][1]
  
  cat("Sheet", i, "columns after cleaning:", colnames(dfS[[i]]), "\n")
}

# fixing ALBI column
dfS[[1]][,2] <- as.numeric(dfS[[1]][,2])  
dfS[[1]] <- dfS[[1]][!is.na(dfS[[1]][,2]), ]#removes rows where ALBI is NA

```

### 2.3 Merge into single timeSeries object [@Tim_prep]

```{r}

# converts first sheet to timeSeries
tsTAA <- timeSeries(dfS[[1]][, 2:ncol(dfS[[1]])], as.Date(dfS[[1]][,1]))
cat("Initial tsTAA dimensions:", dim(tsTAA), "\n")

# merges remaining sheets
for (i in 2:4) {
  tsTmp <- timeSeries(dfS[[i]][, 2:ncol(dfS[[i]])], as.Date(dfS[[i]][,1]))
  tsTAA <- cbind(tsTAA, tsTmp)
  cat("After merging sheet", i, "dimensions:", dim(tsTAA), "\n")
}
# renaming indices for clarity
setFinCenter(tsTAA) <- "Johannesburg"
names(tsTAA)[grep("TS.1.1", names(tsTAA))] <- "ALBI"
names(tsTAA)[grep("TS.1.2", names(tsTAA))] <- "STEFI"
names(tsTAA)[grep("TS.1", names(tsTAA))] <- "ALSI"

cat("Columns after renaming:", colnames(tsTAA), "\n")

#all numeric columns are numeric
for (j in 1:ncol(tsTAA)) {
  tsTAA[, j] <- as.numeric(tsTAA[, j])
}
#remove rows with all NAs
tsTAA <- tsTAA[rowSums(is.na(tsTAA)) < ncol(tsTAA), ]

# Using timeSeries daily2monthly and ensure tsTAA is valid
tsTAA_monthly <- tryCatch(
  daily2monthly(tsTAA),
  error = function(e) {
    stop("Error in daily2monthly: tsTAA might contain non-timeSeries columns or non-numeric values")
  }
)

#  monthly price index
tsIdx  <- index2wealth(tsTAA_monthly)

# geometric monthly returns
tsGRet <- diff(log(tsIdx))

cat("tsTAA_monthly dimensions:", dim(tsTAA_monthly), "\n")
cat("tsGRet dimensions:", dim(tsGRet), "\n")
cat("Columns in tsGRet:\n"); print(colnames(tsGRet))
```

### 2.4 Arithmetic Returns [@Tim_BTmlx]

```{r}

setFinCenter(tsTAA) <- "Africa/Johannesburg"
summary(dfS[[1]][,2])

# Checks that tsTAA is a proper 'timeSeries' object
tsTAA_monthly <- tryCatch(
  daily2monthly(tsTAA),
  error = function(e) {
    message("Error in daily2monthly(): converting tsTAA to xts first")
    xts_obj <- as.xts(tsTAA)
    apply.monthly(xts_obj, colMeans, na.rm=TRUE)
  }
)



#geometric returns
tsGRet <- diff(log(tsTAA_monthly))

#  fill missing data using LOCF
tsGRet_filled <- na.locf(as.xts(tsGRet), na.rm = FALSE)
summary(tsGRet_filled[,"ALBI"])
any(!is.na(tsGRet_filled[,"ALBI"]))

#checking for columns that are all NA
cols_allNA <- colSums(!is.na(tsGRet_filled)) == 0
tsGRet_filled <- tsGRet_filled[, !cols_allNA]

# converting to arithmetic returns
simple_mat <- exp(as.matrix(tsGRet_filled)) - 1
rets_xts <- xts(simple_mat, order.by = index(tsGRet_filled))
colnames(rets_xts) <- colnames(tsGRet_filled)

# Excludes cash asset
cash_idx <- grep("STEFI", colnames(rets_xts), ignore.case = TRUE)
cash_name <- ifelse(length(cash_idx) > 0, colnames(rets_xts)[cash_idx[1]], NA)

rets_opt <- if(!is.na(cash_name)) rets_xts[, -cash_idx, drop=FALSE] else rets_xts
rets_cash <- if(!is.na(cash_name)) rets_xts[, cash_idx, drop=FALSE] else NULL

cat("Assets used for optimisation:\n"); print(colnames(rets_opt))
if(!is.na(cash_name)) cat("Cash excluded from optimisation:", cash_name, "\n")
```

### 2.5 Black-Litterman function [@Tim_BTmlx; @Tim_prep]

```{r}
# ---------------------------------------------------------------------
# Function: blacklitterman
# ---------------------------------------------------------------------
# BLACKLITTERMAN computes the posterior mean vector, posterior covariance
# matrix, and optimal Black–Litterman portfolio weights.
#
# Inputs:
#   Pi      : (n x 1) vector of equilibrium excess returns (prior mean)
#   Sigma   : (n x n) covariance matrix of excess returns
#   P       : (k x n) matrix defining k linear views on asset returns
#   Q       : (k x 1) vector of view returns
#   Omega   : (k x k) diagonal covariance matrix of view uncertainty
#   tau     : scalar (typically small, e.g. 0.05), controls prior confidence
#   gamma   : scalar, risk aversion parameter
#   constrain : logical, if TRUE set negative weights to zero and renormalise
#
# Outputs:
#   A list containing:
#       $weights     - posterior (Black–Litterman) portfolio weights
#       $mu_post     - posterior mean vector E[R | views]
#       $Sigma_post  - posterior covariance matrix Cov[R | views]
#
# ---------------------------------------------------------------------

blacklitterman <- function(Pi, Sigma, P, Q, Omega, tau = 0.05, gamma = 1, constrain = TRUE) {

  # -------------------------------------------------------------------
  # Define matrix dimensions and inverses
  # -------------------------------------------------------------------
  n <- length(Pi)   # number of assets
  Sigma_inv <- solve(Sigma)   # inverse of prior covariance
  Omega_inv <- solve(Omega)   # inverse of view covariance

  # -------------------------------------------------------------------
  # Calculate posterior mean (Black–Litterman expected returns)
  # Formula: μ* = [(τΣ)^(-1) + P'Ω^(-1)P]^(-1)[(τΣ)^(-1)Π + P'Ω^(-1)Q]
  # -------------------------------------------------------------------
  mu_post <- solve(Sigma_inv * tau + t(P) %*% Omega_inv %*% P) %*%
             (Sigma_inv %*% (tau * Pi) + t(P) %*% Omega_inv %*% Q)

  # -------------------------------------------------------------------
  # Calculate posterior covariance matrix
  # Formula: Σ* = Σ + [(τΣ)^(-1) + P'Ω^(-1)P]^(-1)
  # (Note: equivalent to Σ* = [(Σ/τ)^(-1) + P'Ω^(-1)P]^(-1) under scaling)
  # -------------------------------------------------------------------
  Sigma_post <- Sigma + solve(Sigma_inv * tau + t(P) %*% Omega_inv %*% P)

  # -------------------------------------------------------------------
  # optimal portfolio weights
  # Formula: w* = (1/γ) Σ*^(-1) μ*
  # -------------------------------------------------------------------
  w <- solve(gamma * Sigma_post) %*% mu_post

  # -------------------------------------------------------------------
  # non-negativity constraint and normalisation
  # -------------------------------------------------------------------
  if (constrain) {
    w[w < 0] <- 0   # set short positions to zero
    w <- w / sum(w) # re-normalise to full investment
  }

  # -------------------------------------------------------------------
  # Assign asset names 
  # -------------------------------------------------------------------
  w <- as.numeric(w)
  names(w) <- names(Pi)

  return(list(weights = w,
              mu_post = mu_post,
              Sigma_post = Sigma_post))
}


```

### 2.5 a. Test Case
```{r}
Pi <- c(0.25, 0.10, 0.05)
Sigma <- matrix(c(0.09, 0.024, -0.006,
                  0.024, 0.01, 0.0003,
                  -0.006, 0.0003, 0.0025), nrow=3, byrow=TRUE)
P <- matrix(c(1, -1, 0,
              0, 1, -1), nrow=2, byrow=TRUE)
Q <- matrix(c(0.2, -0.05), nrow=2)
Omega <- matrix(c(0.3, 0,
                  0, 0.55), nrow=2)
bl_test <- blacklitterman(Pi, Sigma, P, Q, Omega, tau=0.05, gamma=1, constrain=TRUE)
bl_test$weights
sum(bl_test$weights)

```

### 2.6 Rolling Window Experiment [@Tim_BTmlx; @Tim_prep]

```{r}
### Rolling-window Black-Litterman Backtest 
train.m <- 60  # 5 yr training period
test.m  <- 12  # 1 yr test period
roll_step <- 1 # 1-mthincrements
n_obs <- nrow(rets_opt)
start_idxs <- seq(1, n_obs - train.m - test.m + 1, by=roll_step)
results <- list()
prev_w <- rep(0, ncol(rets_opt)) # initialising previous weights for turnover

# ALSI column for beta calc
benchmark <- tsGRet_filled[, "ALSI", drop=FALSE]

for(i in seq_along(start_idxs)){
  s <- start_idxs[i]
  train_idx <- s:(s+train.m-1)
  tst.idx   <- (s+train.m):(s+train.m+test.m-1)
  
  train_rets <- rets_opt[train_idx, , drop=FALSE]
  tst_rets   <- rets_opt[tst.idx, , drop=FALSE]
  bench_train <- benchmark[train_idx, , drop=FALSE]
  bench_test  <- benchmark[tst.idx, , drop=FALSE]
  
  # invalid windows
  if(any(!is.finite(as.matrix(train_rets))) || any(!is.finite(as.matrix(tst_rets)))) next
  
  mu_train    <- colMeans(train_rets, na.rm=TRUE)
  Sigma_train <- cov(as.matrix(train_rets), use="complete.obs")
  
  # Risk-free
  rf_train <- if(!is.null(rets_cash)) mean(rets_cash[train_idx, ], na.rm=TRUE) else 0
  rf_test  <- if(!is.null(rets_cash)) mean(rets_cash[tst.idx, ], na.rm=TRUE) else 0
  
  # Black-Litterman views
  P <- matrix(0, nrow=1, ncol=ncol(train_rets))
  P[1, 1:3] <- 1/3       # simple view
  Q <- matrix(0.01, nrow=1) # expected 1% return
  Omega <- matrix(0.0001, nrow=1) # view uncertainty
  
  bl_res <- blacklitterman(Pi=mu_train, Sigma=Sigma_train, P=P, Q=Q, Omega=Omega, tau=0.05, gamma=3,constrain=FALSE)
  
  # Constraint weights: no short, fully invested 
  w_hat <- bl_res$weights
  w_hat[w_hat < 0] <- 0
  w_hat <- w_hat / sum(w_hat)
  
  turnover <- sum(abs(w_hat - prev_w))
  prev_w <- w_hat
  
  # Portfolio returns 
  port_train <- as.numeric(as.matrix(train_rets) %*% w_hat)
  port_test  <- as.numeric(as.matrix(tst_rets) %*% w_hat)
  
  # Tracking Error relative to ALSI 
port_diff <- port_test - as.numeric(bench_test)
t.err <- sd(port_diff, na.rm = TRUE)
  
  # Jensen Alpha & Beta relative to ALSI 
xcess.p.train  <- port_train  - rf_train
xcess.b.train <- as.numeric(bench_train) - rf_train
CAPM_train <- lm(xcess.p.train ~ xcess.b.train)
alpha_IS <- coef(CAPM_train)[1]
beta_IS  <- coef(CAPM_train)[2]

# OOS excess returns
excess_port_test  <- port_test  - rf_test
excess_bench_test <- as.numeric(bench_test) - rf_test

CAPM_test <- lm(excess_port_test ~ excess_bench_test)
alpha_OOS <- coef(CAPM_test)[1]
beta_OOS  <- coef(CAPM_test)[2]
  
  # Cumulative equity curve 
eq_curve_test <- cumprod(1 + port_test)
  
  # Results
  results[[length(results)+1]] <- list(
  train_period = paste(index(train_rets)[1], index(train_rets)[nrow(train_rets)], sep=" / "),
  test_period  = paste(index(tst_rets)[1], index(tst_rets)[nrow(tst_rets)], sep=" / "),
  mu_IS = mean(port_train, na.rm=TRUE),
  var_IS = var(port_train, na.rm=TRUE),
  SR_IS = (mean(port_train, na.rm=TRUE) - rf_train)/sqrt(var(port_train, na.rm=TRUE)),
  mu_OOS = mean(port_test, na.rm=TRUE),
  var_OOS = var(port_test, na.rm=TRUE),
  SR_OOS = (mean(port_test, na.rm=TRUE) - rf_test)/sqrt(var(port_test, na.rm=TRUE)),
  alpha_IS = alpha_IS,
  beta_IS = beta_IS,
  alpha_OOS = alpha_OOS,
  beta_OOS = beta_OOS,
  turnover = turnover,
  t.err = t.err,   
  eq_curve_test = eq_curve_test,
  weights = w_hat,
  assets  = colnames(rets_opt)
)

}

# makes it easier to plot
summary_df <- do.call(rbind, lapply(results, function(x) data.frame(
  train=x$train_period, test=x$test_period,
  mu_IS=x$mu_IS, var_IS=x$var_IS, SR_IS=x$SR_IS,
  mu_OOS=x$mu_OOS, var_OOS=x$var_OOS, SR_OOS=x$SR_OOS,
  alpha_IS=x$alpha_IS, beta_IS=x$beta_IS,
  alpha_OOS=x$alpha_OOS, beta_OOS=x$beta_OOS,
  turnover=x$turnover,
  t.err = x$t.err   
)))


knitr::kable(summary_df,
  digits = 4,
  caption = "In-sample vs Out-of-sample BL Portfolio Statistics"
)


```

### 2.7 Portfolio Turnover
```{r}
turnover_df <- data.frame(
  Window = 1:length(results),
  Turnover = sapply(results, function(x) x$turnover)
)

# Portfolio Turnover per Rolling Window
ggplot(turnover_df, aes(x = Window, y = Turnover)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "",
       x = "Rolling Window", y = "Turnover") +
  theme_minimal()

```


### 2.8 Jensens alpha and beta
```{r}
# in-sample and out-of-sample Alpha and Beta
ab_df <- data.frame(
  Window = 1:length(results),
  alpha_IS = sapply(results, function(x) x$alpha_IS),
  alpha_OOS = sapply(results, function(x) x$alpha_OOS),
  beta_IS = sapply(results, function(x) x$beta_IS),
  beta_OOS = sapply(results, function(x) x$beta_OOS)
)

# In-Sample vs. Out-of-Sample Jensen's Alpha
ggplot(ab_df, aes(x = Window)) +
  geom_line(aes(y = alpha_IS, color = "In-Sample"), linewidth = 0.9) +
  geom_line(aes(y = alpha_OOS, color = "Out-of-Sample"), linewidth = 0.9) +
  labs(title = "",
       x = "Rolling Window", y = "Alpha", color = "Sample Type") +
  theme_minimal() +
  scale_color_manual(values = c("In-Sample" = "darkgreen", "Out-of-Sample" = "darkblue"))

# In-Sample vs. Out-of-Sample Portfolio Beta
ggplot(ab_df, aes(x = Window)) +
  geom_line(aes(y = beta_IS, color = "In-Sample"), linewidth = 0.9) +
  geom_line(aes(y = beta_OOS, color = "Out-of-Sample"), linewidth = 0.9) +
  labs(title = "",
       x = "Rolling Window", y = "Beta", color = "Sample Type") +
  theme_minimal() +
  scale_color_manual(values = c("In-Sample" = "darkred", "Out-of-Sample" = "darkorange"))

```

### 2.9 Plotting In Sample vs Out Of Sample Statistics

```{r}
library(tidyr)
summary_df <- do.call(rbind, lapply(seq_along(results), function(i) {
  x <- results[[i]]
  data.frame(
    Window = i,  
    train = x$train_period,
    test = x$test_period,
    mu_IS = x$mu_IS, var_IS = x$var_IS, SR_IS = x$SR_IS,
    mu_OOS = x$mu_OOS, var_OOS = x$var_OOS, SR_OOS = x$SR_OOS,
    alpha_IS = x$alpha_IS, beta_IS = x$beta_IS,
    alpha_OOS = x$alpha_OOS, beta_OOS = x$beta_OOS,
    turnover = x$turnover,
    t.err = x$t.err
  )
}))
sum_l <- summary_df %>%
  pivot_longer(
    cols = c(mu_IS, var_IS, SR_IS, mu_OOS, var_OOS, SR_OOS),
    names_to = "Metric",
    values_to = "Value"
  ) %>%
  mutate(
    Sample = ifelse(grepl("_IS", Metric), "In-Sample", "Out-of-Sample"),
    Metric = gsub("_(IS|OOS)", "", Metric),
    Metric = case_when(
      Metric == "mu" ~ "Mean",
      Metric == "var" ~ "Variance",
      Metric == "SR" ~ "Sharpe",
      TRUE ~ Metric
    )
  )


# Mean
ggplot(subset(sum_l, Metric == "Mean"),
       aes(x = Window, y = Value, color = Sample, linetype = Sample)) +
  geom_line(linewidth = 0.9) +
  labs(
    title = "",
    x = "Rolling Window",
    y = "Mean Return"
  ) +
  theme_minimal()

# Variance 
ggplot(subset(sum_l, Metric == "Variance"),
       aes(x = Window, y = Value, color = Sample, linetype = Sample)) +
  geom_line(linewidth = 0.9) +
  labs(
    title = "",
    x = "Rolling Window",
    y = "Variance"
  ) +
  theme_minimal()

# Sharpe Ratio 
ggplot(subset(sum_l, Metric == "Sharpe"),
       aes(x = Window, y = Value, color = Sample, linetype = Sample)) +
  geom_line(linewidth = 0.9) +
  labs(
    title = "",
    x = "Rolling Window",
    y = "Sharpe Ratio"
  ) +
  theme_minimal()




```



### 2.10 Portfolio Weights
```{r}
# Combine all rolling window weights into a single data frame
weights_df <- do.call(rbind, lapply(seq_along(results), function(i) {
  data.frame(
    Window = i, #index
    Asset  = results[[i]]$assets,# asset names
    Weight = results[[i]]$weights,#  weights
    stringsAsFactors = FALSE
  )
}))

# Evolution of Black-Litterman Portfolio Weights
ggplot(weights_df, aes(x = Window, y = Asset, fill = Weight)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue") +
  scale_x_continuous(
    breaks = seq(min(weights_df$Window), max(weights_df$Window), by = 5)
  ) +
  labs(
    title = "",
    x = "Rolling Window Index",
    y = "Asset",
    fill = "Weight"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```



### 2.11 Tracking Error
```{r}
### Tracking Error Plot
t.err_df <- data.frame(
  Window = 1:length(results),
  TrackingError = sapply(results, function(x) x$t.err)
)
# Rolling Window Tracking Error vs ALSI
ggplot(t.err_df, aes(x = Window, y = TrackingError)) +
  geom_line(linewidth = 0.9) +
  geom_hline(yintercept = 0.03, linetype="dashed") +
  geom_hline(yintercept = 0.10, linetype="dashed") +
  labs(title = "",
       x = "Rolling Window", y = "Tracking Error") +
  theme_minimal()

```

\newpage
# References
